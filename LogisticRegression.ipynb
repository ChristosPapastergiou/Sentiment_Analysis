{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":62857,"databundleVersionId":6886092,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ---- Includes ----\n\nimport re\nimport nltk\nimport spacy\nimport pickle\nimport optuna\nimport scikitplot\nimport matplotlib\nimport unicodedata\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nnltk.download(\"punkt\")         # Download to be able to use word_tokenize from nltk library\n\n!pip install optuna            # Download to be able to use Optuna as hyper-parameter\n!python -m spacy download el   # Download to be able to lemmatize greek words using spacy\n!pip install greek-stemmer-pos # Download to be able to use stem on greek words\n\nfrom tabulate import tabulate\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom greek_stemmer import stemmer\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import cross_validate, GridSearchCV, train_test_split\nfrom sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-14T10:45:36.115052Z","iopub.execute_input":"2023-11-14T10:45:36.115412Z","iopub.status.idle":"2023-11-14T10:46:42.109902Z","shell.execute_reply.started":"2023-11-14T10:45:36.115382Z","shell.execute_reply":"2023-11-14T10:46:42.108062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Datasets","metadata":{}},{"cell_type":"code","source":"# ---- Reading the datasets ----\n\ndf_test = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/test_set.csv\")\ndf_train = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/train_set.csv\")\ndf_valid = pd.read_csv(\"/kaggle/input/ys19-2023-assignment-1/valid_set.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:46:46.962943Z","iopub.execute_input":"2023-11-14T10:46:46.963426Z","iopub.status.idle":"2023-11-14T10:46:47.361491Z","shell.execute_reply.started":"2023-11-14T10:46:46.963387Z","shell.execute_reply":"2023-11-14T10:46:47.360282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data pre-processing","metadata":{}},{"cell_type":"code","source":"# ---- NaN values ----\n\ndf_test.dropna(inplace = True)   # Good practice to\ndf_train.dropna(inplace = True)  # remove all empty   \ndf_valid.dropna(inplace = True)  # values of the datasets","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:46:59.438020Z","iopub.execute_input":"2023-11-14T10:46:59.438433Z","iopub.status.idle":"2023-11-14T10:46:59.462599Z","shell.execute_reply.started":"2023-11-14T10:46:59.438401Z","shell.execute_reply":"2023-11-14T10:46:59.461744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- Stopwords ----\n\nnltk.download(\"stopwords\")\nnlp = spacy.load('el_core_news_sm')\n\nspacy_greek_stopwords = nlp.Defaults.stop_words       # Greek stopwords from spacy\nnltk_greek_stopwords = set(stopwords.words(\"greek\"))  # Greek stopwords from nltk\n\nenglish_stopwords = set(stopwords.words(\"english\"))\ngreek_stopwords = spacy_greek_stopwords.union(nltk_greek_stopwords) # Combination of those so there is a bigger list of stopwords","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:47:01.154969Z","iopub.execute_input":"2023-11-14T10:47:01.155574Z","iopub.status.idle":"2023-11-14T10:47:02.165173Z","shell.execute_reply.started":"2023-11-14T10:47:01.155533Z","shell.execute_reply":"2023-11-14T10:47:02.160862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- Cleansing / Tokenizing ----\n\nmapping_names = {\n    \"αλεξη\" : \"αλεξης\",\n    \"τσιπρα\" : \"τσιπρας\",\n    \"συριζας\" : \"συριζα\",\n    \"κουλη\" : \"κυριακος\",\n    \"κουλης\" : \"κυριακος\",\n    \"κυριακο\" : \"κυριακος\",\n    \"μητσοτακη\" : \"μητσοτακης\",\n}\n\ndef replace_words(text):\n    words = text.split()                                                # If the word is inside the dictionary (map for names)\n    replaced_words = [mapping_names.get(word, word) for word in words]  # change it. Lemmatizer can't convert those names and if \n    return ' '.join(replaced_words)                                     # there's no usage of lemmatizer names must be equal\n\ndef split_connected(text):\n    english_letters = r'[A-Za-z]+'\n    greek_letters = r'[Α-Ωα-ωίϊΐόάέύϋΰήώ]+'\n    \n    greek = re.findall(greek_letters, text)     # Go and find the greek and the english \n    english = re.findall(english_letters, text) # words based on the patern above\n    \n    return ' '.join(english + greek)  # End combine them to have cleaner text. For example \"Greekεκλογες\" will be \"Greek εκλογες\"\n\ndef remove_accent(text):\n    normalized = unicodedata.normalize('NFD', text)                              # Using unicodedata to decompose characters\n    new_text = [char for char in normalized if not unicodedata.combining(char)]  # with tones or any accent and be able to keep\n    return ''.join(new_text)\n\ndef stem_text(text):\n    words = text.split()                                               # Split the text into words\n    stemmed_words = [stemmer.stem_word(word,\"VBG\") for word in words]  # stem every word of the text \n    return ' '.join(stemmed_words)                                     # and join all text pieces\n\ndef lemmatize_text(text):\n    tokens = nlp(text)                                     # Tokenize the text\n    lemmatized_words = [token.lemma_ for token in tokens]  # then apply lemmatization\n    return ' '.join(lemmatized_words)                      # and join all the tokens\n\ndef text_cleaning(column):\n    column = column.str.lower()                                # All to lowercase first\n    column = column.str.replace(r'[@#]', '', regex = True)     # Remove all mentions and hashtags\n    column = column.str.replace(r'www\\S+', '', regex = True)   # Remove anything that \n    column = column.str.replace(r'http\\S+', '', regex = True)  # has to do with links \n    column = column.str.replace(r'[^\\w\\s]', '', regex = True)  # Remove all punctuation marks\n       \n    column = column.apply(split_connected)\n    \n    column = column.apply(lambda x: ' '.join(x.split())) # Replace consecutive whitespaces so the resulting description will contain a single space between words\n    column = column.apply(lambda x: re.sub(r'(.)\\1{2,}', r'\\1\\1', x)) # Replace 3 or more same consecutive characters by 2 using regular expressions (e.g balll will become ball)\n    column = column.apply(lambda x: ' '.join([word for word in x.split() if word not in greek_stopwords]))   # Remove greek stopwords\n    column = column.apply(lambda x: ' '.join([word for word in x.split() if word not in english_stopwords])) # Remove english stopwords\n\n#     column = column.apply(stem_text)\n#     column = column.str.lower()\n#     column = column.apply(lemmatize_text)\n    column = column.apply(remove_accent)\n    column = column.apply(replace_words)\n    \n    return column\n\ndf_test['Text'] = text_cleaning(df_test['Text'])\ndf_train['Text'] = text_cleaning(df_train['Text'])\ndf_valid['Text'] = text_cleaning(df_valid['Text'])\n\ndf_train['Tokens'] = df_train['Text'].apply(word_tokenize)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:47:07.403969Z","iopub.execute_input":"2023-11-14T10:47:07.404487Z","iopub.status.idle":"2023-11-14T10:47:16.843715Z","shell.execute_reply.started":"2023-11-14T10:47:07.404448Z","shell.execute_reply":"2023-11-14T10:47:16.842466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Analysis","metadata":{}},{"cell_type":"code","source":"# ---- Pie Plots ----\n\nplt.figure(figsize = (20, 8))\n\n# What is the distribution of the sentiment\ntotal_sentiment_distribution = df_train['Sentiment'].value_counts()\n\nplt.subplot(1, 3, 1)\ntotal_sentiment_distribution.plot(kind = 'pie', autopct = '%1.1f%%')\nplt.title('Sentiments')\n\n# Whats the total votes every party has\ntotal_votes_party = df_train['Party'].value_counts()\n\nplt.subplot(1, 3, 2)\ntotal_votes_party.plot(kind = 'pie', autopct = lambda p: '{:.0f}'.format(p * total_votes_party.sum() / 100))\nplt.title('Party Votes')\n\n# How many positive sentiments each party has\npositive_sentiment_party = df_train[df_train['Sentiment'] == 'POSITIVE']['Party'].value_counts()\n\nplt.subplot(1, 3, 3)\npositive_sentiment_party.plot(kind = 'pie', autopct = lambda p: '{:.0f}'.format(p * positive_sentiment_party.sum() / 100))\nplt.title('Positive Sentiments by Party')\n\n# Show all analysis #\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:47:27.270721Z","iopub.execute_input":"2023-11-14T10:47:27.271148Z","iopub.status.idle":"2023-11-14T10:47:27.871048Z","shell.execute_reply.started":"2023-11-14T10:47:27.271115Z","shell.execute_reply":"2023-11-14T10:47:27.869895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- Bar Plots ----\n\nplt.figure(figsize = (20, 8))\n\ndef find_top_words(column):\n    count = Counter(word for words in column for word in words)      # Calculate word frequencies using Counter\n    top_words = count.most_common(15)                                # and select the top 10 of them to show\n    return pd.DataFrame(top_words, columns = ['Word', 'Frequency'])  # Create a DataFrame for plotting\n\n# Top words used on Tweeter for the Greek Elections \ntop_tweet_words = find_top_words(df_train['Tokens'])\n\nplt.bar(top_tweet_words['Word'], top_tweet_words['Frequency'])\nplt.xticks(rotation = 40)\nplt.title('Top words Tweeted')\nplt.xlabel('Word')\nplt.ylabel('Frequency')\n\n# Show all analysis #\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:47:35.810679Z","iopub.execute_input":"2023-11-14T10:47:35.811100Z","iopub.status.idle":"2023-11-14T10:47:36.322596Z","shell.execute_reply.started":"2023-11-14T10:47:35.811063Z","shell.execute_reply":"2023-11-14T10:47:36.321846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- WordCloud for all dataset's text ----\n\nplt.figure(figsize = (20, 8))\n\ncloud = WordCloud(width = 800, height = 400, background_color = 'black').generate(' '.join(df_train['Text']))\n\nplt.imshow(cloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.title('WordCloud')","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:47:40.451370Z","iopub.execute_input":"2023-11-14T10:47:40.451865Z","iopub.status.idle":"2023-11-14T10:47:46.652019Z","shell.execute_reply.started":"2023-11-14T10:47:40.451826Z","shell.execute_reply":"2023-11-14T10:47:46.650990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- WordCloud for each Party ----\n\nplt.figure(figsize = (20, 5))\n\nparties = df_train['Party'].unique()\n\nfig, axes = plt.subplots(nrows = (len(parties) // 3) + (len(parties) % 3 > 0), ncols = 3, figsize = (18, 6)) # Many word clouds so split for plotting\n\nfor i, party in enumerate(parties, start = 1):\n    cloud = WordCloud(width = 800, height = 400, background_color = 'black').generate(' '.join(df_train[df_train['Party'] == party]['Text']))\n    \n    if len(parties) > 3:    # In a dataset im not\n        row = (i - 1) // 3  # sure how many parties there \n        col = (i - 1) % 3   # are maybe it will come in handy\n        ax = axes[row, col]\n    else:\n        ax = axes[i - 1]\n    \n    ax.imshow(cloud, interpolation = 'bilinear')\n    ax.axis('off')\n    ax.set_title(f'{party} Word Cloud')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:47:51.559173Z","iopub.execute_input":"2023-11-14T10:47:51.559659Z","iopub.status.idle":"2023-11-14T10:48:02.766376Z","shell.execute_reply.started":"2023-11-14T10:47:51.559622Z","shell.execute_reply":"2023-11-14T10:48:02.765518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- WordCloud for each Sentiment ----\n\nplt.figure(figsize = (20, 5))\n\nsentiments = df_train['Sentiment'].unique()\n\nfig, axes = plt.subplots(nrows = (len(sentiments) // 3) + (len(sentiments) % 3 > 0), ncols = 3, figsize = (18, 6))\n\nfor i, sentiment in enumerate(sentiments, start = 1):\n    cloud = WordCloud(width = 800, height = 400, background_color = 'black').generate(' '.join(df_train[df_train['Sentiment'] == sentiment]['Text']))\n    \n    if len(sentiments) > 3: # In a dataset im not\n        row = (i - 1) // 3  # sure how many sentiments there\n        col = (i - 1) % 3   # are maybe it will come in handy\n        ax = axes[row, col]\n    else:\n        ax = axes[i - 1]\n    \n    ax.imshow(cloud, interpolation = 'bilinear')\n    ax.axis('off')\n    ax.set_title(f'{sentiment} Word Cloud')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:48:07.793075Z","iopub.execute_input":"2023-11-14T10:48:07.793516Z","iopub.status.idle":"2023-11-14T10:48:16.060667Z","shell.execute_reply.started":"2023-11-14T10:48:07.793480Z","shell.execute_reply":"2023-11-14T10:48:16.059811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- Word Cloud based on parties ----\n\nplt.figure(figsize = (20, 8))\n\n# WordCloud for the top 3 Political Parties\ncolumn = df_train[df_train['Party'].isin(['SYRIZA', 'ND', 'PASOK'])]['Text']\ncloud = WordCloud(width = 800, height = 400, background_color = 'black').generate(' '.join(column))\n\nplt.imshow(cloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.title('Top 3 Parties Word Cloud')","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:48:19.229717Z","iopub.execute_input":"2023-11-14T10:48:19.231066Z","iopub.status.idle":"2023-11-14T10:48:24.526905Z","shell.execute_reply.started":"2023-11-14T10:48:19.231017Z","shell.execute_reply":"2023-11-14T10:48:24.525742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data partitioning","metadata":{}},{"cell_type":"code","source":"# ---- Train / Valid (Test) ----  \n\nX_train = df_train['Text']\nY_train = df_train['Sentiment']  # Vectorizer can handle the sentiments\n\nX_valid = df_valid['Text']\nY_valid = df_valid['Sentiment']","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:48:28.142198Z","iopub.execute_input":"2023-11-14T10:48:28.143745Z","iopub.status.idle":"2023-11-14T10:48:28.151603Z","shell.execute_reply.started":"2023-11-14T10:48:28.143674Z","shell.execute_reply":"2023-11-14T10:48:28.150243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vectorization","metadata":{}},{"cell_type":"code","source":"# ---- Fit & Transform ----\n\nvectorizer = TfidfVectorizer()\ntrain_features = vectorizer.fit_transform(X_train)  # Fit and transform the X_train \nvalid_features = vectorizer.transform(X_valid)      # Transform the X_valid","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:48:29.918597Z","iopub.execute_input":"2023-11-14T10:48:29.919073Z","iopub.status.idle":"2023-11-14T10:48:30.851424Z","shell.execute_reply.started":"2023-11-14T10:48:29.919037Z","shell.execute_reply":"2023-11-14T10:48:30.850341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification","metadata":{}},{"cell_type":"code","source":"# ---- Scores to be calculated based on the model ----\n\nscoring = {'precision' : make_scorer(precision_score, average = 'macro', zero_division = 1),\n           'recall' : make_scorer(recall_score, average = 'macro', zero_division = 1),\n           'f1' : make_scorer(f1_score, average = 'macro', zero_division = 1), \n           'accuracy' : 'accuracy'}","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:48:33.359828Z","iopub.execute_input":"2023-11-14T10:48:33.360213Z","iopub.status.idle":"2023-11-14T10:48:33.365660Z","shell.execute_reply.started":"2023-11-14T10:48:33.360184Z","shell.execute_reply":"2023-11-14T10:48:33.364441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- Model creation-training and results ----\n\nmodel = LogisticRegression(max_iter = 1000)  # Using Logistic regression as classification algorithm    \nmodel.fit(train_features, np.ravel(Y_train))\n\naccuracy = accuracy_score(np.ravel(Y_valid), model.predict(valid_features))\nf1 = f1_score(np.ravel(Y_valid), model.predict(valid_features), average = 'macro')                 # To have better match using\nrecall = recall_score(np.ravel(Y_valid), model.predict(valid_features), average = 'macro')         # macro both to predict \nprecision = precision_score(np.ravel(Y_valid), model.predict(valid_features), average = 'macro')   # and to the cross validation\n                          \nvalid_scores = cross_validate(model, valid_features, np.ravel(Y_valid), cv = 10, scoring = scoring)\n\ntable = [[\"Method\", \"Accuracy\", \"F1-Score\", \"Recall\", \"Precision\"],\n         [\"Predict\", accuracy, f1, recall, precision],\n         [\"Cross Validation\", valid_scores['test_accuracy'].mean(), valid_scores['test_f1'].mean(), valid_scores['test_recall'].mean(), valid_scores['test_precision'].mean()]]\n\nprint(tabulate(table, headers = 'firstrow', tablefmt = 'fancy_grid'))","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:48:35.511900Z","iopub.execute_input":"2023-11-14T10:48:35.512286Z","iopub.status.idle":"2023-11-14T10:49:50.099542Z","shell.execute_reply.started":"2023-11-14T10:48:35.512255Z","shell.execute_reply":"2023-11-14T10:49:50.098207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyper-parameters","metadata":{}},{"cell_type":"code","source":"# ---- Using GridSearch ----\n\nparameters = {'C': [0.01, 0.1, 1], 'solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'], 'max_iter': [1000, 10000]} # All the wanted parameters want to check\ngrid_search = GridSearchCV(LogisticRegression(), parameters, cv = 10, scoring = 'accuracy')\ngrid_search.fit(train_features, np.ravel(Y_train))\nbest_parameters = grid_search.best_params_\n\nbest_c_grid = best_parameters['C']\nbest_solver_grid = best_parameters['solver']\nbest_iteration_grid = best_parameters['max_iter']\n\nprint(\"Best parameters: \", best_parameters)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T10:50:02.903973Z","iopub.execute_input":"2023-11-14T10:50:02.904397Z","iopub.status.idle":"2023-11-14T11:02:35.858393Z","shell.execute_reply.started":"2023-11-14T10:50:02.904362Z","shell.execute_reply":"2023-11-14T11:02:35.857046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- Using Optuna ----\n\ndef objective(trial):\n    C = trial.suggest_float('C', 1e-3, 1e3, log = True)\n    max_iter = trial.suggest_int('max_iter', 1000, 10000)\n    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'])\n    \n    model = LogisticRegression(C = C, solver = solver, max_iter = max_iter)\n    model.fit(train_features, np.ravel(Y_train))\n    \n    scores = cross_validate(model, valid_features, np.ravel(Y_valid), cv = 10, scoring = 'accuracy')  # in order to have trusted scores using cross\n    \n    return scores['test_score'].mean()\n    \nstudy = optuna.create_study(direction = 'maximize', study_name = 'Christos study')\nstudy.optimize(objective, n_trials = 100)\nbest_parameters = study.best_params\n\nbest_c_optuna = best_parameters['C']\nbest_solver_optuna = best_parameters['solver']\nbest_iteration_optuna = best_parameters['max_iter']\n\nprint(\"Best hyperparameters:\", best_parameters)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T11:02:43.953680Z","iopub.execute_input":"2023-11-14T11:02:43.954176Z","iopub.status.idle":"2023-11-14T11:46:15.044710Z","shell.execute_reply.started":"2023-11-14T11:02:43.954137Z","shell.execute_reply":"2023-11-14T11:46:15.042531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification using Hyper-parameters","metadata":{}},{"cell_type":"code","source":"# ---- Model creation and results using Grid Search's best parameters ----\n\nmodel = LogisticRegression(C = best_c_grid, solver = best_solver_grid, max_iter = best_iteration_grid) # Using Logistic regression as classification algorithm          \nmodel.fit(train_features, np.ravel(Y_train))\n\naccuracy = accuracy_score(np.ravel(Y_valid), model.predict(valid_features))\nf1 = f1_score(np.ravel(Y_valid), model.predict(valid_features), average = 'macro')                 # To have better match using\nrecall = recall_score(np.ravel(Y_valid), model.predict(valid_features), average = 'macro')         # macro both to predict \nprecision = precision_score(np.ravel(Y_valid), model.predict(valid_features), average = 'macro')   # and to the cross validation                 \n                          \nvalid_scores = cross_validate(model, valid_features, np.ravel(Y_valid), cv = 10, scoring = scoring)\n\ntable = [[\"Method\", \"Accuracy\", \"F1-Score\", \"Recall\", \"Precision\"],\n         [\"Predict\", accuracy, f1, recall, precision],\n         [\"Cross Validation\", valid_scores['test_accuracy'].mean(), valid_scores['test_f1'].mean(), valid_scores['test_recall'].mean(), valid_scores['test_precision'].mean()]]\n\nprint(tabulate(table, headers = 'firstrow', tablefmt = 'fancy_grid'))","metadata":{"execution":{"iopub.status.busy":"2023-11-14T11:46:23.555694Z","iopub.execute_input":"2023-11-14T11:46:23.556220Z","iopub.status.idle":"2023-11-14T11:46:26.381677Z","shell.execute_reply.started":"2023-11-14T11:46:23.556172Z","shell.execute_reply":"2023-11-14T11:46:26.369041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- Model creation and results using Optuna's best parameters ----\n\nmodel = LogisticRegression(C = best_c_optuna, solver = best_solver_optuna, max_iter = best_iteration_optuna) # Using Logistic regression as classification algorithm          \nmodel.fit(train_features, np.ravel(Y_train))\n\naccuracy = accuracy_score(np.ravel(Y_valid), model.predict(valid_features))\nf1 = f1_score(np.ravel(Y_valid), model.predict(valid_features), average = 'macro')                 # To have better match using\nrecall = recall_score(np.ravel(Y_valid), model.predict(valid_features), average = 'macro')         # macro both to predict \nprecision = precision_score(np.ravel(Y_valid), model.predict(valid_features), average = 'macro')   # and to the cross validation                 \n                          \nvalid_scores = cross_validate(model, valid_features, np.ravel(Y_valid), cv = 10, scoring = scoring)\n\ntable = [[\"Method\", \"Accuracy\", \"F1-Score\", \"Recall\", \"Precision\"],\n         [\"Predict\", accuracy, f1, recall, precision],\n         [\"Cross Validation\", valid_scores['test_accuracy'].mean(), valid_scores['test_f1'].mean(), valid_scores['test_recall'].mean(), valid_scores['test_precision'].mean()]]\n\nprint(tabulate(table, headers = 'firstrow', tablefmt = 'fancy_grid'))","metadata":{"execution":{"iopub.status.busy":"2023-11-14T11:46:29.523531Z","iopub.execute_input":"2023-11-14T11:46:29.524092Z","iopub.status.idle":"2023-11-14T11:47:03.308583Z","shell.execute_reply.started":"2023-11-14T11:46:29.524035Z","shell.execute_reply":"2023-11-14T11:47:03.307520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AUC, Learning Curve, Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# ---- ROC Curve / AUC Score ----\n\nauc = np.round(roc_auc_score(np.ravel(Y_valid), model.predict_proba(valid_features), multi_class = 'ovo'), 3)\nprint(\"Total AUC: \", auc)\n\nscikitplot.metrics.plot_roc(np.ravel(Y_valid), model.predict_proba(valid_features))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T11:47:23.750927Z","iopub.execute_input":"2023-11-14T11:47:23.751357Z","iopub.status.idle":"2023-11-14T11:47:24.138811Z","shell.execute_reply.started":"2023-11-14T11:47:23.751319Z","shell.execute_reply":"2023-11-14T11:47:24.137631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- Learning Curve ----\n\nlist_samples = []\nlist_f1_train = []\nlist_f1_validation = []\n\nfor times in range(10):\n    X, X_unused, Y, Y_unused = train_test_split(train_features, Y_train, test_size = 1 - (times * 0.1 + 0.001))\n\n    model = LogisticRegression(max_iter = 1000)\n#     model = LogisticRegression(C = best_c_optuna, solver = best_solver_optuna, max_iter = best_iteration_optuna) # For better results using the hyper-parameters\n    model.fit(X, np.ravel(Y))\n\n    f1_train = f1_score(np.ravel(Y), model.predict(X), average = 'macro')\n    f1_validation = f1_score(np.ravel(Y_valid), model.predict(valid_features), average = 'macro')\n    \n    print(\"F1 Score Train: \", str(f1_train))\n    print(\"F1 Score Validation: \", str(f1_validation))\n\n    list_f1_train.append(f1_train)\n    list_f1_validation.append(f1_validation)\n    \n    list_samples.append((times * 0.1 + 0.1))\n\nplt.plot(list_samples, list_f1_validation)\nplt.plot(list_samples, list_f1_train)\n\nplt.ylim(ymin = 0)\nplt.legend([\"Validation\", \"Training\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-14T11:47:27.275463Z","iopub.execute_input":"2023-11-14T11:47:27.275952Z","iopub.status.idle":"2023-11-14T11:49:32.490839Z","shell.execute_reply.started":"2023-11-14T11:47:27.275914Z","shell.execute_reply":"2023-11-14T11:49:32.489680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- Confusion Matric ----\n\nconfusion_martix = metrics.confusion_matrix(np.ravel(Y_valid), model.predict(valid_features))\n\nsns.heatmap(confusion_martix, annot = True, fmt = \"d\", cmap = 'coolwarm')\nplt.ylabel('Prediction', fontsize = 13)\nplt.xlabel('Actual', fontsize = 13)\nplt.title('Confusion Matrix', fontsize = 17)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:41:55.954431Z","iopub.execute_input":"2023-11-13T22:41:55.954989Z","iopub.status.idle":"2023-11-13T22:41:56.316230Z","shell.execute_reply.started":"2023-11-13T22:41:55.954952Z","shell.execute_reply":"2023-11-13T22:41:56.314999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Predictions","metadata":{}},{"cell_type":"code","source":"X_test = df_test['Text']\n\ntest_features = vectorizer.transform(X_test) # Transform the X_test like X_valid\npredictions = model.predict(test_features)   # previously and based on the model make predictions\n\ndf_test['Sentiments'] = predictions\n\ndf_test.head(30)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:41:59.153923Z","iopub.execute_input":"2023-11-13T22:41:59.154492Z","iopub.status.idle":"2023-11-13T22:41:59.427851Z","shell.execute_reply.started":"2023-11-13T22:41:59.154447Z","shell.execute_reply":"2023-11-13T22:41:59.426589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_predictions = df_test[['New_ID', 'Sentiments']]                                            # The dataset to output needs only\ndf_predictions = df_predictions.rename(columns = {'New_ID': 'Id', 'Sentiments': 'Predicted'}) # the 2 columns of sentiments and ids\ndf_predictions.to_csv(\"submission.csv\", index = False)\n\ndf_predictions.head(30)","metadata":{"execution":{"iopub.status.busy":"2023-11-13T22:42:05.134644Z","iopub.execute_input":"2023-11-13T22:42:05.135161Z","iopub.status.idle":"2023-11-13T22:42:05.186936Z","shell.execute_reply.started":"2023-11-13T22:42:05.135123Z","shell.execute_reply":"2023-11-13T22:42:05.185573Z"},"trusted":true},"execution_count":null,"outputs":[]}]}